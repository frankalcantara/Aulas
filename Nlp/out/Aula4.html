<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="author" content="Frank Coelho de Alcantara -2020" />
  <title>Word2Vector</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta
    name="apple-mobile-web-app-status-bar-style"
    content="black-translucent" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" />
  <link rel="stylesheet" href="../../rev/reset.css" />
  <link rel="stylesheet" href="../../rev/reveal.css" />
  <link rel="stylesheet" href="../../rev/interpret.css" />
</head>

<body>
  <div class="reveal">
    <div class="slides">
      <section id="title-slide" class="nivel1">
       <section>
        <h1 class="title" style="width: 90%; margin-left: 4%; font-size: 340%;">Word2Vector</h1>
        <p style="text-align: right !important;">Frank Coelho de Alcantara -2020&nbsp;&nbsp;</p>
       </section>
       <section>
          <h2>Vetorização</h2>
          <small style="font-size: 73% !important; margin-left: 0%; width: 95%;">
            <p  class="fragment fade-up">Algoritmo de aprendizagem supervisionada para a vetorização criado em 2013.</p>
            <p  class="fragment fade-up">Mikolov, Tomas; et al. (2013). "Efficient Estimation of Word Representations in Vector Space". <a href="https://arxiv.org/archive/cs.CL" target="_blank" rel="noopener noreferrer">arXiv:1301.3781</a>.</p>
            <p  class="fragment fade-up">Mikolov, Tomas (2013). "Distributed representations of words and phrases and their compositionality". Advances in Neural Information Processing Systems. <a href="https://arxiv.org/abs/1310.4546" target="_blank" rel="noopener noreferrer">arXiv:1310.4546</a>.</p>
            <p  class="fragment fade-up">O objetivo é criar vetores menos esparsos e mais uteis para descobrir a relação entre termos em documentos.</p>
          </small>
        </section>
        <section>
          <h2>Matriz Esparsa</h2>
          <small style="font-size: 73% !important; margin-left: 0%; width: 95%;">
            <p  class="fragment fade-up">Já vimos que a vetorização cria matrizes que relacionam termos e documentos de uma forma esparsa.</p>
            <p  class="fragment fade-up">Ainda que exista informação nesta representação, perdemos semântica e criamos grandes matrizes cheias de zeros.</p>
            <p  class="fragment fade-up">Por outro lado, criamos vetores que representam documentos em um espaço multidimensional onde cada termo é uma dimensão.</p>
            <p  class="fragment fade-up">Podemos ver a relação entre os vetores de cada documento usando a distância entre eles.</p>
            <p  class="fragment fade-up">Dois documentos exatamente iguais terão o mesmo comprimento e o ângulo entre eles será zero. O ângulo é importante. Muito importante.</p>
          </small>
        </section>
        <section>
          <h2><i>Cossine Similarity</i></h2>
          <small style="font-size: 54% !important; margin-left: -2%; width: 49%;">
            <p  class="fragment fade-up">Métrica utilizada para determinar o grau de similaridade entre dois documentos independente dos seus tamanhos.</p>
            <p  class="fragment fade-up">Mediremos o cosseno do ângulo entre dois vetores em um espaço multidimensional.</p>
            <p  class="fragment fade-up">No nosso caso, dois vetores são estruturas de dados contendo informações sobre os dois documentos.</p>
            <p  class="fragment fade-up">Cada termo corresponde a uma dimensão e a quantidade destes termos indica o escalar da dimensão. E podemos determinar a orientação do vetor que representa o texto.</p>
            <p  class="fragment fade-up">Usando o cosseno entre os ângulos podemos criar uma medida de similaridade entre os vetores criados independente do comprimento destes vetores.</p>
          </small>
          <img data-src="../img/w2v1.jpg" class="fragment fade-up" style="margin-right: 1%; height: 360px !important; float: right;"  alt="gráfico mostrando um vetor entre a origem e o ponto (1,2,3)." />
        </section>
        <section>
          <h2>Cossine Similarity - Matemática</h2>
          <small style="font-size: 61% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">A Similaridade entre dois vetores, $A$ e $B$ será dada por: 
              $$cos(\theta) = \frac{A\cdot B}{|A||B|} $$ </p>
            <p  class="fragment fade-up">Ou, considerando as múltiplas dimensões teremos: $$cos(\theta)= \frac{\sum_{i=1}^{n}A_i B_i}{\sqrt{\sum_{i=1}^{n}A_i} \sqrt{\sum_{i=1}^{n}A_i}}$$</p>
            <p  class="fragment fade-up">O qué bastante simples usando o <i>Numpy</i> $$cos\_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))$$</p>
          </small>
         </section>
         <section>
          <h2>Word2Vector - CBOW</h2>
          <small style="float: left; font-size: 61% !important; margin-left: 0%; width: 50%;">
            <p  class="fragment fade-up">Word2Vector usa dois algoritmos para a criação do vetor: CBOW e SKIP-GRAM</p>
            <p  class="fragment fade-up"><strong>CBOW</strong> <i>Common Bag Of Words</i>: considera o contexto de um determinado termo e tenta inferir 
            que termo é este.</p>
            <p  class="fragment fade-up">Funciona com a determinação de uma janela, um conjunto de palavras e dentro desta janela, centraliza a palavra desejada.</p>
            <p  class="fragment fade-up">Trata-se de um algoritmo de aprendizagem supervisionada consistindo de uma rede neural com três camadas com apenas uma camada oculta.</p>
            <p  class="fragment fade-up">Você pode ver uma implementação deste algoritmo em python, usando o Keras <a href="https://analyticsindiamag.com/the-continuous-bag-of-words-cbow-model-in-nlp-hands-on-implementation-with-codes/" target="_blank" rel="noopener noreferrer">aqui!</a></p>
          </small>
          <img data-src="../img/w2v2.jpg" class="fragment fade-up" style="margin-right: 1%; height: 360px !important; float: right;"  alt="diagrama em blocos de uma rede neural apresentando três camadas." />
         </section>
         <section>
          <h2>Word2Vector - SKIP-GRAM</h2>
          <small style="float: left; font-size: 61% !important; margin-left: 0%; width: 50%;">
            <p  class="fragment fade-up"><strong>SKIP-GRAM</strong>: partindo de um termo determinado o Skip-Gram tenta determinar os termos que rodeiam este termo.</p>
            <p  class="fragment fade-up">Funciona com a determinação de uma janela, e vai criar os termos que estão dentro desta janela em torno do termo chave. É o processo inverso ao CBOW</p>
            <p  class="fragment fade-up">Trata-se de um algoritmo de aprendizagem supervisionada consistindo de uma rede neural com três camadas com apenas uma camada oculta.</p>
            <p  class="fragment fade-up">Você pode ver uma implementação deste algoritmo em python <a href="https://www.geeksforgeeks.org/implement-your-own-word2vecskip-gram-model-in-python/" target="_blank" rel="noopener noreferrer">aqui!</a></p>
          </small>
          <img data-src="../img/w2v2.jpg" class="fragment fade-up" style="margin-right: 1%; height: 360px !important; float: right;"  alt="diagrama em blocos de uma rede neural apresentando três camadas." />
         </section>
         <section>
          <h2>Word2Vector - Completo</h2>
          <small style="float: left; font-size: 61% !important; margin-left: 0%; width: 50%;">
            <p  class="fragment fade-up">o <strong>Word2Vector</strong> usa estes dois algoritmos com a intensão de criar um vetor a partir de um determinado corpus. </p>
            <p  class="fragment fade-up">Tanto o CBOW quanto o SKIP-GRAM são usados apenas para descobrir as informações que criarão um vetor mais próximo de algum sentido semântico.</p>
            <p  class="fragment fade-up">A dimensão do vetor é o número de features que temos na saída.</p>
            <p  class="fragment fade-up">Esta imagem está disponível <a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
              " target="_blank" rel="noopener noreferrer">aqui!</a></p>
          </small>
          <img data-src="../img/w2v1.png" class="fragment fade-up" style="margin-right: 1%; height: 295px !important; float: right;"  alt="diagrama em blocos de uma rede neural apresentando três camadas." />
         </section>
         <section>
          <h2>Exercício 1</h2>
          <small style="font-size: 73% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Seu trabalho será, usando o Google Colab, determinar a similaridade, usando <i>Cossine Similarity</i> entre todos os  documentos formados por um corpus de dois arquivos científicos, quaisquer, com mais de 15 páginas em PDF, escritos em inglês e convertidos para txt com a ferramenta que você desejar.</p>
            <p  class="fragment fade-up">O resultado deve ser uma matriz relacionando estes parágrafos e a sua similaridade.</p>
            <p  class="fragment fade-up">Este trabalho vale a presença para as aulas de 11 de novembro e 18 de novembro.</p>
          </small>
         </section>
         <section>
          <h2>Exercício 2</h2>
          <small style="font-size: 73% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Seu trabalho será, usando o Google Colab, fazer uma implementação, <i>from scratch</i> do CBOW.</p>
            <p  class="fragment fade-up">O resultado deve ser uma rede neural que, dado um conjunto de 4 palavras indique a palavra mais provável de estar 
              exatamente no meio. Treine seu algoritmo com os textos do Machado de Assis disponíveis na NLTK</p>
            <p  class="fragment fade-up">Este trabalho vale a presença para as aulas de 11 de novembro e 18 de novembro.</p>
          </small>
         </section>
         <section>
          <h2>Exercício 2</h2>
          <small style="font-size: 73% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Seu trabalho será, usando o Google Colab, fazer uma implementação, <i>from scratch</i> do SKIP-GRAM.</p>
            <p  class="fragment fade-up">O resultado deve ser uma rede neural que, dado um termo indique as quatro palavras mais prováveis de estar 
              circundando este termo. Treine seu algoritmo com os textos do Machado de Assis disponíveis na NLTK</p>
            <p  class="fragment fade-up">Este trabalho vale a presença para as aulas de 11 de novembro e 18 de novembro.</p>
          </small>
         </section>
    </section>
    <section class="nivel1">
      <section >
        <h1 class="title" style="width: 90%; margin-left: 4%; font-size: 340%;">Bag of Words</h1>
      </section>
      <section>
        <h2>Bag of Words</h2>
        <small style="font-size: 73% !important; margin-left: 0%; width: 97%;">
          <p  class="fragment fade-up">Chamamos de <i>bag of words</i> ou BOW por que o resultado não leva a sintaxe do corpus em consideração.</p>
          <p  class="fragment fade-up">Só tem sentido se o corpus tiver várias sentenças.</p>
          <p  class="fragment fade-up">Usa como base para a vetorização a frequência de ocorrência de lexemas em todo o corpus.</p>
          <p  class="fragment fade-up">Chamaremos o corpus de lista de BOW e o resultado será uma matriz Termo-Documento.</p>
          <p  class="fragment fade-up">Usaremos Termo em lugar de lexema e cada sentença do corpus será um documento.</p>
        </small>
       </section>
       <section>
        <h2>Vocabulário</h2>
        <small style="font-size: 73% !important; margin-left: 0%; width: 97%;">
          <p  class="fragment fade-up">Este é o primeiro passo, encontraremos a frequência de ocorrência de todos os termos existentes no corpus.</p>
          <p  class="fragment fade-up">Faremos isso sem nenhuma técnica de redução de dimensionalidade, nada de stopwords, lemmatization ou stemming.</p>
          <p  class="fragment fade-up">Considere o corpus:</p>
          <ol style="margin-left:7%;">
            <li  class="fragment fade-up">A carteira colocou a carteira na carteira.</li>
            <li  class="fragment fade-up">O carteiro não tem carteira.</li>
            <li  class="fragment fade-up">O carteiro comprou uma carteira nova.</li>
          </ol>
          <p  class="fragment fade-up">Nosso vocabulário tem 12 termos $\{A, carteira, colocou, na, a, O, carteiro, \\ não, tem, comprou, uma, nova\}$</p>
        </small>
       </section>
       <section>
       <h2>Criação de Vetores</h2>
       <small style="font-size: 64% !important; margin-left: 0%; width: 97%;">
         <p  class="fragment fade-up">Temos um corpus composto de 3 documentos:</p>
         <ol style="margin-left:7%;">
          <li  class="fragment fade-up">A carteira colocou a carteira na carteira.</li>
          <li  class="fragment fade-up">O carteiro não tem carteira.</li>
          <li  class="fragment fade-up">O carteiro comprou uma carteira nova.</li>
        </ol>
         <p  class="fragment fade-up">Nosso vocabulário tem 12 termos $\{A, carteira, colocou, na, a, O, carteiro, \\ não, tem, comprou, uma, nova\}$</p>
         <p  class="fragment fade-up">Criamos um vetor para cada documento no corpus colocando a quantidade de vezes que uma palavra aparece no documento na posição que ela está no vocabulário.</p>
         <ol style="margin-left:7%;">
           <li  class="fragment fade-up">$[1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]$</li>
           <li  class="fragment fade-up">$[0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]$</li>
           <li  class="fragment fade-up">$[0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]$</li>
         </ol>
       </small>
      </section>
      <section>
        <h2>Exercício 1</h2>
        <small style="font-size: 64% !important; margin-left: 0%; width: 97%;">
          <p  class="fragment fade-up">Tente sozinho, no papel, com o corpus:</p>
          <ol style="margin-left:7%;">
           <li  class="fragment fade-up">São Paulo não ensinou em São Paulo.</li>
           <li  class="fragment fade-up">Se tivesse ensinado, São Paulo seria Paulista.</li>
           <li  class="fragment fade-up">São Paulo é a capital de São Paulo.</li>
         </ol>
          <p  class="fragment fade-up">Encontre o vocabulário e defina o vetor para cada sentença.</p>
        </small>
       </section>
       <section>
        <h2>Matriz Termo-Documento</h2>
          <p>Trata-se da matriz construída com todos os vetores dos documentos que compõem o corpus.</p>
          <table style="font-size: 48%;">
            <tr style="background-color: gray;">
              <td style="background-color: gray;">Doc</td> 
              <td style="background-color: gray;">A</td>
              <td style="background-color: gray;">carteira</td>
              <td style="background-color: gray;">colocou</td>
              <td style="background-color: gray;">na</td>
              <td style="background-color: gray;">a</td>
              <td style="background-color: gray;">O</td>
              <td style="background-color: gray;">carteiro</td>
              <td style="background-color: gray;">não</td>
              <td style="background-color: gray;">tem</td>
              <td style="background-color: gray;">comprou</td>
              <td style="background-color: gray;">uma</td>
              <td style="background-color: gray;">nova</td>
            </tr>
            <tr>
              <td>$1$</td>
              <td>$1$</td> 
              <td>$3$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
            </tr>
            <tr>
              <td>$2$</td> 
              <td>$0$</td>
              <td>$1$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
            </tr>
            <tr>
              <td>$3$</td> 
              <td>$0$</td> 
              <td>$1$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$0$</td>
              <td>$0$</td>
              <td>$1$</td>
              <td>$1$</td>
              <td>$1$</td>
            </tr>
          </table>
        <p>A matriz gerada pelos $n$ documentos que compõem o corpus é, geralmente, esparsa e de alta dimensionalidade obedecendo a <i><b>Lei de Zipf</b></i> .</p>
       </section>
       <section>
        <h2>Lei de Zipf</h2>
        <small style="font-size: 50% !important; margin-left: 0%; width: 97%;">
          <p  class="fragment fade-up">Um dos fatos mais interessantes no estudo da linguagem natural, e também um dos mais básicos é que os termos ocorrem, nas sentenças, 
            seguindo uma distribuição de frequências sistemática, simples, de tal forma que existem poucos termos com alta frequência e estes constituem a maior parte dos termos em um corpus.</p>
          <p  class="fragment fade-up"> George Kingsley Zipf, em seu livro <i>The psycho-biology of language: An introduction to dynamic philology</i>de 1999. percebeu que a enézima palvra mais 
            frequente de um determinado texto tem uma frequência dada por $$f(n) \approx  \frac{1}{n^\alpha}$$</p>
            <p  class="fragment fade-up">Nesta equação o $n$ representa a colocação do termo na classificação dos termos em ordem de frequência, as maiores primeiro. Mandelbrot, em 
              <i>An informational theory of the statistical structure of language</i> revisou esta fórmula e lhe deu a forma que usamos atualmente: $$f(n) \approx  \frac{1}{(n+\beta)^\alpha}$$ </p>
            <p  class="fragment fade-up">Para $\alpha \approx 1$ e $\beta \approx 2.7$ esta fórmula parece ser verdadeira para todos os idiomas humanos e talvez seja uma característica da comunicação na nossa espécie.</p>
        </small>
       </section>
       <section>
        <h2>Problemas com <i>Bag of Words</i></h2>
        <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
          <p  class="fragment fade-up"><strong>Vocabulário</strong>: requer cuidado e atenção e frequentemente o uso de eliminação da pontuação, <i>stopwords</i> e adequação ao contexto.</p>
          <p  class="fragment fade-up"><strong>Matriz Esparsa</strong>: difícil de modelar, pouca informação em muito espaço.</p>
          <p  class="fragment fade-up"><strong>Significado</strong>: quando ignoramos a ordem das palavras perdemos o sentido do termo <i>(bag of n-grams?)</i></p>
          <p  class="fragment fade-up">Profissionalmente é raro ver o Bow, implementado com um algoritmo tão simples quanto o que vimos. Muitas vezes ele está agregado do <b>TF-IDF</b></p>
        </small>
       </section>
      </section>
      <section class="nivel1">
        <section>
          <h1 class="title" style="width: 90%; margin-left: 4%; font-size: 340%;">TF-IDF</h1>
        </section>
        <section>
          <h2>TF-IDF</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">TF-IDF (<i>Term Frequency – Inverse Document Frequency</i>) é usado para medir a importância de um termo em um documento presente em uma coleção de documentos.  
              O valor TF-IDF de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um documento. 
              Porém, este valor é relativizado pela frequência da palavra no corpus. Resumindo: </p>
              <blockquote>Quanto mais frequentemente um termo ocorre em um documento, mais representativo ele é para o conteúdo, e em quanto mais documentos o termo ocorre, menos discriminativo ele é. </blockquote>
          </small>
        </section>
        <section>
          <h2>Corpus</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Para entender este algoritmo vamos usar o seguinte corpus:</p>
            <ol style="margin-left:7%;">
              <li  class="fragment fade-up">A carteira colocou a carteira na carteira.</li>
              <li  class="fragment fade-up">O carteiro não tem carteira.</li>
              <li  class="fragment fade-up">O carteiro comprou uma carteira nova.</li>
            </ol>
            <p class="fragment fade-up">Que resulta na seguinte matriz:</p>
            <table  class="fragment fade-up" style="font-size: 69%;">
              <tr style="background-color: gray;">
                <td style="background-color: gray;">Doc</td> 
                <td style="background-color: gray;">A</td>
                <td style="background-color: gray;">carteira</td>
                <td style="background-color: gray;">colocou</td>
                <td style="background-color: gray;">na</td>
                
                <td style="background-color: gray;">a</td>
                <td style="background-color: gray;">O</td>
                <td style="background-color: gray;">carteiro</td>
                <td style="background-color: gray;">não</td>
                <td style="background-color: gray;">tem</td>
                <td style="background-color: gray;">comprou</td>
                <td style="background-color: gray;">uma</td>
                <td style="background-color: gray;">nova</td>
              </tr>
              <tr>
                <td>$1$</td>
                <td>$1$</td> 
                <td>$3$</td>
                <td>$1$</td>
                <td>$1$</td>
               
                <td>$1$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
              </tr>
              <tr>
                <td>$2$</td> 
                <td>$0$</td>
                <td>$1$</td>
                <td>$0$</td>
                <td>$0$</td>
                
                <td>$0$</td>
                <td>$1$</td>
                <td>$1$</td>
                <td>$1$</td>
                <td>$1$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
              </tr>
              <tr>
                <td>$3$</td> 
                <td>$0$</td> 
                <td>$1$</td>
                <td>$0$</td>
                <td>$0$</td>
                
                <td>$0$</td>
                <td>$1$</td>
                <td>$1$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$1$</td>
                <td>$1$</td>
                <td>$1$</td>
              </tr>
            </table>
          </small>
        </section>
        <section>
          <h2>TF</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">A Frequência de um Termo (TF): fornece a frequência de cada termo em um documento do corpus. e pode ser calculada por: 
              $$tf_{i,j} = \frac{n_{i,j}}{\Sigma_k n_{i,j}}$$
            </p>
            <p  class="fragment fade-up">Onde $n_{i,j}$, representa a frequência de um lexema $i$ em um documento $j$. De uma forma mais simples podemos dizer que para um 
              determinado termo $t$, de um documento $d$ seu $tf$ será dado por: $$tf_{(t,d)} = \frac{quantidade\_de\_t\_em\_d}{numero\_de\_termos\_em\_d}$$</p>
          </small>
        </section>
        <section>
          <h2>TF - Exemplo</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Dado o seguinte corpus:</p>
            <ol style="margin-left:7%;">
              <li  class="fragment fade-up">A carteira colocou a carteira na carteira.</li>
              <li  class="fragment fade-up">O carteiro não tem carteira.</li>
              <li  class="fragment fade-up">O carteiro comprou uma carteira nova.</li>
            </ol>
            <p class="fragment fade-up">Que resulta na seguinte matriz:</p>
            <table  class="fragment fade-up" style="font-size: 45%;">
              <tr style="background-color: gray;">
                <td style="background-color: gray;">Doc</td> 
                <td style="background-color: gray;">Termos</td> 
                <td style="background-color: gray;">A</td>
                <td style="background-color: gray;">carteira</td>
                <td style="background-color: gray;">colocou</td>   
                <td style="background-color: gray;">na</td>
                <td style="background-color: gray;">a</td>
                <td style="background-color: gray;">O</td>
                <td style="background-color: gray;">carteiro</td>
                <td style="background-color: gray;">não</td>
                <td style="background-color: gray;">tem</td>
                <td style="background-color: gray;">comprou</td>
                <td style="background-color: gray;">uma</td>
                <td style="background-color: gray;">nova</td>
              </tr>
              <tr>
                <td>$1$</td>
                <td>$7$</td>
                <td>$1/7 \\ = 0,14$</td> 
                <td>$3/7 \\  = 0,43$</td>
                <td>$1/7 \\  = 0,14$</td>
                <td>$1/7 \\  = 0,14$</td>
                <td>$1/7 \\  = 0,14$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
              </tr>
              <tr>
                <td>$2$</td> 
                <td>$5$</td>
                <td>$0$</td>
                <td>$1/5 \\  = 0,2$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$1/5 \\  = 0,2$</td>
                <td>$1/5 \\  = 0,2$</td>
                <td>$1/5 \\  = 0,2$</td>
                <td>$1/5 \\  = 0,2$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
              </tr><tr>
                <td>$3$</td> 
                <td>$6$</td> 
                <td>$0$</td>
                <td>$1/6 \\  = 0,17$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$1/6 \\  = 0,17$</td>
                <td>$1/6 \\  = 0,17$</td>
                <td>$0$</td>
                <td>$0$</td>
                <td>$1/6 \\  = 0,17$</td>
                <td>$1/6 \\  = 0,17$</td>
                <td>$1/6 \\  = 0,17$</td>
              </tr>
            </table>
          </small>
        </section>
        <section>
          <h2>IDF</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">Cálculo do IDF (Inverse Document Frequency): permite computar o peso de 
              cada palavra na coleção de documentos. Palavras que ocorrem mais raramente tem maior IDF: $$idf_{(t)} = log(\frac{N}{df_t +1})$$
            </p>
            <p  class="fragment fade-up">Para o nosso caso teremos:</p>
            <table  class="fragment fade-up" style="font-size: 39%;">
              <tr style="background-color: gray;">
                <td style="background-color: gray;">A</td>
                <td style="background-color: gray;">carteira</td>
                <td style="background-color: gray;">colocou</td>   
                <td style="background-color: gray;">na</td>
                <td style="background-color: gray;">a</td>
                <td style="background-color: gray;">O</td>
              </tr>
              <tr>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(5+1))) = 1,23$</td> 
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(2+1)) = 0$</td>
                <td>$log(3/(2+1)) = 0$</td>
              </tr>
              <tr style="background-color: gray;">
                <td style="background-color: gray;">carteiro</td>
                <td style="background-color: gray;">não</td>
                <td style="background-color: gray;">tem</td>
                <td style="background-color: gray;">comprou</td>
                <td style="background-color: gray;">uma</td>
                <td style="background-color: gray;">nova</td>
              </tr>
              <tr>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
                <td>$log(3/(1+1)) = 0,18$</td>
              </tr>
            </table>
          </small>
        </section>
        <section>
          <h2>TF-IDF Finalmente</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <p  class="fragment fade-up">A fórmula final é o produto das duas fórmulas anteriores $$tfidf_{(i,j)} =\frac{n_{i,j}}{\Sigma_k n_{i,j}} \times log(\frac{N}{df_t +1})$$
            </p>
            <p  class="fragment fade-up">Que calculará o TF-IDF o termo $i$ para o documento $j$.</p>
            <p  class="fragment fade-up">O resultado desta operação, sobre nosso corpus de exemplo pode ser visto no próximo slide.</p>
           </small>
        </section>
        <section>
          <h2>TF-IDF Resultado</i></h2>
          <small style="font-size: 80% !important; margin-left: 0%; width: 97%;">
            <table  class="fragment fade-up" style="font-size: 43%;">
              <tr style="background-color: gray;">
                <td style="background-color: gray;">Doc</td> 
                <td style="background-color: gray;">A</td>
                <td style="background-color: gray;">carteira</td>
                <td style="background-color: gray;">colocou</td>   
                <td style="background-color: gray;">na</td>
                <td style="background-color: gray;">a</td>
                <td style="background-color: gray;">O</td>
              </tr>
              <tr>
                <td>$1$</td>
                <td>$0,14 * 0,18 = 0,03$</td> 
                <td>$0,43 * 1,23 = 0,53$</td>
                <td>$0,14 * 0,18 = 0,03$</td>
                <td>$0,14 * 0,18 = 0,03$</td>
                <td>$0,14 * 0 = 0$</td>
                <td>$0 * 0 = 0$</td>
              </tr>
              <tr>
                <td>$2$</td> 
                <td>$0 * 0,18 = 0$</td>
                <td>$0,2 * 1,23 = 2,5$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0 = 0$</td>
                <td>$0,2 * 0 = 0$</td>
                </tr>
                <tr>
                <td>$3$</td> 
                <td>$0 * 0,18 = 0$</td>
                <td>$0,17 * 1,23 = 0,21$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0 = 0$</td>
                <td>$0,17 * 0 = 0$</td>
              </tr>
              <tr style="background-color: gray;">
                <td style="background-color: gray;">Doc</td> 
                <td style="background-color: gray;">carteiro</td>
                <td style="background-color: gray;">não</td>
                <td style="background-color: gray;">tem</td>
                <td style="background-color: gray;">comprou</td>
                <td style="background-color: gray;">uma</td>
                <td style="background-color: gray;">nova</td>
              </tr>
              <tr>
                <td>$1$</td>
                <td>$0 * 0 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
              </tr>
              <tr>
                <td>$2$</td> 
                <td>$0,2 * 0,18 = 0,04$</td>
                <td>$0,2 * 0,18 = 0,04$</td>
                <td>$0,2 * 0,18 = 0,04$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
              </tr><tr>
                <td>$3$</td> 
                <td>$0,17 * 0,18 = 0,31$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0 * 0,18 = 0$</td>
                <td>$0,17 * 0,18 = 0,31$</td>
                <td>$0,17 * 0,18 = 0,31$</td>
                <td>$0,17 * 0,18 = 0,31$</td>
              </tr>
              </table>
           </small>
        </section>
      </section>  
    </section>
    </div>
  </div>
  <div class="home-button"><a href="https://frankalcantara.com"><i class="fas fa-home"></i></a></div>
  <script src="../../rev/reveal.js"></script>
  <script src="../../rev/plugin/notes/notes.js"></script>
  <script src="../../rev/plugin/search/search.js"></script>
  <script src="../../rev/plugin/zoom/zoom.js"></script>
  <script src="../../rev/plugin/math/math.js"></script>
  <script src="../../rev/plugin/menu/menu.js"></script>
  <script src="../../rev/plugin/chalkboard/plugin.js"></script>

  <script>
    // Full list of configuration options available at:
    // https://revealjs.com/config/
    Reveal.initialize({
      // Push each slide change to the browser history
      history: true,
      // Transition style
      transition: "fade", // none/fade/slide/convex/concave/zoom
      center: false,
      math: {
        mathjax:
          "https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js",
        config: "TeX-AMS_HTML-full",
        // pass other options into `MathJax.Hub.Config()`
        TeX: {
          Macros: {
            RR: "{\\bf R}",
          },
        },
      },
      menu: {
        side: "left",
        width: "normal",
        numbers: false,
        titleSelector: "h1, h2, h3, h4, h5, h6",
        useTextContentForMissingTitles: false,
        hideMissingTitles: false,
        markers: true,
        custom: false,
        themes: false,
        themesPath: "dist/theme/",
        transitions: false,
        openButton: true,
        openSlideNumber: false,
        keyboard: true,
        sticky: false,
        autoOpen: true,
        delayInit: false,
        openOnInit: false,
        loadIcons: true,
      },

      // reveal.js plugins
      plugins: [
        RevealNotes,
        RevealMath,
        RevealMenu,
        RevealChalkboard,
        RevealSearch,
        RevealZoom,
      ],
    });
  </script>
</body>

</html>