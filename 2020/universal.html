<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>WebAssembly and the Elusive Universal Binary</title>

<!--
WebAssembly and the Elusive Universal Binary

Many software developers dream of a "universal binary" that would let us build
once and ship everywhere. Of course such a thing would be impossible to do
without some tradeoffs on speed or portability, but it's worth getting as close
as we can! In this talk we'll see how WebAssembly can help here both today and
in the future.
-->

    <meta name="description" content="Wasm and the Elusive Universal Binary">
    <meta name="author" content="Alon Zakai">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css" id="theme">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">

    <style type="text/css">
      h2 b {
        color: #f48;
      }
      h3 b {
        color: #f9c;
      }
      b {
        color: #af3;
      }
      strong {
        color: #9af;
      }
    </style>
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h2><b>WebAssembly and the Elusive Universal Binary</b></h2>
          <p>
            June 2020
          </p>
          <p>
            Alon Zakai (Google)
          </p>
        </section>

        <section>
          <p>
            A "<b>Universal Binary</b>" is a single executable that
            runs on any arch and any OS, and
            runs at 100% of speed.
          </p>
          <hr>
          <p>
            The dream is you build once instead of for each target, and
            despite having a single portable build, it's not noticeably slower.
          </p>
          <hr>
          <p>
            In fact, it doesn't need to actually be a <strong>binary</strong>, so long as it's
            portable and fast.
          </p>
        </section>

        <section>
          <h3><b>Example: My Use Case</b></h3>
          <p>
            <a href="https://github.com/WebAssembly/binaryen#tools">wasm-opt</a>
            shrinks wasm files by around <b>20%</b> on average.
          </p>
          <hr>
            Binary builds are used by tools like Emscripten and wasm-pack.
            We have builds for Linux, Mac, and Windows, and most users are happy with those.
          </p>
          <hr>
          <p>
            But some users can't use them, for example if they are on BSD or
            a weird Linux.
            And build infra takes work, sometimes tests only fail there, etc.
          </p>
        </section>

        <section>
          <p>
            It would be nice if we had this:
          </p>
          <hr>
          <pre><code class="bash" data-trim>
$ make output # or any other build system
...
$ run output # on other machines too!
...
</code></pre>
        </section>

        <section>
          <h3><b>Can we do that..?</b></h3>
          <p>
            Or rather, how close can we get today?
          </p>
          <p>
            And how close can we get eventually?
          </p>
        </section>

        <section>
          <h3><b>Portability</b></h3>
          <p>
            First, let's distinguish two types of portability.
          </p>
          <hr>
          <p>
            <b>CPU portability</b> concerns <strong>pure computation</strong>, lets you run your code no matter what the
            CPU architecture is.
          </p>
          <hr>
          <p>
            <b>OS portability</b> concerns <strong>APIs</strong>, and lets you do operations like
            printing, file access, etc. no matter the operating system.
          </p>
        </section>

        <section>
          <p>
            <b>The Web</b> has one of the best CPU + OS portability stories. Browser-specific
            bugs definitely exist, and are annoying, but given the scale of the Web
            they are remarkably few!
          </p>
          <hr>
          <p>
            <strong>Node.js, Python, Java, .NET</strong>, and other virtual machines (VMs) provide full
            CPU portability, and some amount of OS portability. Some operations
            are OS-specific; less portable, but more power.
          </p>
          <hr>
          <p>
            On the Web, use WebAssembly + JavaScript. Off the Web, we should use one of those VMs.
          </p>
        </section>

        <section>
          <p>
            If we have <b>C, C++, Rust, or Go</b>, what VMs can we compile to?
          </p>
          <hr>
          <p>
            All those can compile to <b>WebAssembly</b> which solves CPU
            portability! That leaves the API question.
          </p>
        </section>

        <section>
          <p>
            <b>In a console environment</b> there are two main ways to run wasm today:
          </p>
          <hr>
          <p>
            <strong>Node.js</strong>: Very popular VM built on the V8 JavaScript (JS)
            engine. Supports both JS and wasm, and combining
            them is easy.
          </p>
          <hr>
          <p>
            <strong>Wasm VMs</strong>: A new family of VMs built on various wasm
            engines, including:
            <a href="https://github.com/bytecodealliance/wasmtime">Wasmtime</a>,
            <a href="https://github.com/wasmerio/wasmer">Wasmer</a>,
            <a href="https://github.com/WAVM/WAVM">WAVM</a>,
            <a href="https://github.com/wasm3/wasm3">wasm3</a>, etc.
          </p>
        </section>

        <section>
          <h3><b>WebAssembly APIs</b></h3>
          <hr>
          <p>
            On the Web, wasm uses <strong>Web APIs</strong>, just connect it through JS.
          </p>
          <hr>
          <p>
            Off the Web, the main options are <b>Node.js APIs</b>, <b>WASI APIs</b>,
            and <b>custom embedding APIs</b>.
          </p>
        </section>

        <section>
          <h3><b>1. Node.js APIs</b></h3>
          <p>
            Node.js APIs are a useful set of OS operations on things like
            <a href="https://nodejs.org/api/fs.html">files</a> and
            <a href="https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options">processes</a> (spawn, fork, etc.).
          </p>
          <hr>
          <pre><code class="js" data-trim>
// No special sandboxing model; like Python etc.,
// this gives the program a reasonably-portable
// set of OS operations.
const fs = require("fs");
const data = fs.readFileSync("data.dat");
// Can provide imports to wasm that use these indirectly.
</code></pre>
        </section>

        <section>
          <h3><b>2. WASI APIs</b></h3>
          <p>
            The <a href="https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/">WebAssembly System Interface</a>,
            meant for non-Web environments.
          </p>
          <hr>
          <p>
            WASI is <b>not</b> just a bunch of familiar APIs brought to wasm! It is a
            new approach to writing an OS interface layer, a replacement for
            something like POSIX.
          </p>
          <hr>
          <p>
            In particular WASI uses <a href="https://en.wikipedia.org/wiki/Capability-based_security">capability-based security</a>.
          </p>
        </section>

        <section>
          <h3><b>3. Custom embedding APIs</b></h3>
          <hr>
          <p>
            For example, a game engine with wasm plugins may provide APIs to the engine's
            internals.
          </p>
        </section>

        <section>
          <h3><b>The future</b></h3>
          <p>
            Custom APIs will always exist, but otherwise in the long term
            WASI will likely be the best option for the things it can support.
          </p>
          <hr>
          <p>
            Node.js is also adding WASI support.
          </p>
          <hr>
          <p>
            But WASI is still fairly new, designing a new OS API takes time,
            and the strict sandboxing will limit what can be done.
          </p>
        </section>

        <section>
          <h3><b>Compiling to WASM VMs?</b></h3>
          <p>
            <b>wasm-opt</b> needs C++ exceptions or setjmp in the interpreter
            component (to unwind the stack; the interpreter is used when
            optimizing so that we can check every expression if we can compute
            it at compile time).
          </p>
          <hr>
          <p>
            WASI doesn't support setjmp or C++ exceptions yet, so that's not an
            option (yet!)
          </p>
        </section>

        <section>
          <h3><b>Compiling to wasm on node.js</b></h3>
          <hr>
          <p>
            Building it with Emscripten is very easy:
          </p>
          <pre><code class="bash" data-trim>
$ emcmake cmake .
$ make -j8 wasm-opt
</code></pre>
          <hr>
          <p>
            And so is running it:
          </p>
          <pre><code class="bash" data-trim>
$ node wasm-opt.js input.wasm -O -o output.wasm
# note the size improvement
$ ls -lh input.wasm output.wasm 
-rw-r--r-- 23K input.wasm
-rw-r--r-- 18K output.wasm
</code></pre>
        </section>

        <section>
          <p>
            That mostly worked out of the box, but by default Emscripten's
            output is designed to run in a browser, and is sandboxed. To get
            direct local file access in node, we need <strong>-s NODERAWFS</strong>.
          </p>
          <hr>
          <p>
            That's it! Then <b>node wasm-opt.js</b> runs the same as a normal native
            executable would.
          </p>
        </section>

        <section>
          <p>
            <b>The good:</b> It has full CPU portability, and as it only does simple file reading
            and writing Node.js APIs give us full OS portability too!
          </p>
          <hr>
          <p>
            <b>The reasonable:</b> Throughput is just 28% slower than native.
          </p>
          <hr>
          <p>
            <b>The bad:</b> A startup delay is noticeable, about 1 second. Really noticeable for
            running a test suite with lots of invocations!
          </p>
        </section>

        <section>
          <p>
            The real solution for startup is
            <a href="https://v8.dev/blog/wasm-code-caching">wasm code caching</a>,
            which works on the Web, but not yet on Node.js.
          </p>
          <hr>
          <p>
            Node 12 had an API for code caching (in Emscripten we added
            <b>-s NODE_CODE_CACHING</b>) but that
            <a href="https://github.com/nodejs/node/issues/18265#issuecomment-622971547">needs reworking</a>
            in Node 14, so it isn't possible atm.
          </p>
        </section>

        <section>
          <p>
            Maybe we don't need wasm? We can compile to JS and rely on
            JS's super-fast startup!
          </p>
          <hr>
          </p>
            Linking with <b>-s WASM=0</b> tells Emscripten to run wasm2js which
            compiles the wasm to JS.
          </p>
          <hr>
          <p>
            Speeds up startup by almost 2x!
            But as you would expect, throughput is 2x slower...
          </p>
        </section>

        <section>
          <h3><b>The story so far</b></h3>
          <p>
            <ul>
              <li>Can't do WASI since no setjmp support</li>
              <li>Can't do wasm on Node since startup is slower</li>
              <li>Can't do JS on Node since throughput is slower</li>
            </ul>
          </p>
          <hr>
          <p>
            Maybe we should give up?
          </p>
        </section>

        <section>
          <h3><b>wasm2c</b></h3>
          <hr>
          <p>
            original source <b>&rightarrow;</b> wasm <b>&rightarrow;</b> C "source" <b>&rightarrow;</b> native
          </p>
          <hr>
          <p>
            Very easy to do!
<!--  also atm           -s STANDALONE_WASM" -->
          <pre><code class="bash" data-trim>
            # tell emscripten to use wasm2c
            $ emcmake cmake . "-DCMAKE_EXE_LINKER_FLAGS=-s WASM2C"
            $ make -j8
            # build the output C normally
            $ clang wasm-opt.wasm.c -O2 -lm -o wasm-opt
            $ ./wasm-opt # runs like a normal executable!
          </code></pre>
          </p>
        </section>

        <section>
          <h3><b>VM-less wasm</b></h3>
          <hr>
          <p>
            Startup is instantaneous, exactly like a normal executable!
          </p>
          <hr>
          <p>
            Throughput is just 13% slower (half the overhead of the wasm from earlier) thanks to full clang/gcc etc. optimizations!
          </p>
          <hr>
          <p>
            All the portability and sandboxing of wasm, but without a VM, and
            better speed.
          </p>
        </section>

        <section>
          <p>
            Wait, isn't all this a little silly? We started with C++, compiled
            to wasm, then back to C? We still need to compile that C!
          </p>
          <hr>
          <p>
            <table>
              <tr>
                <td><strong>Dev machine:</strong></td><td><center>source <b>&rightarrow;</b> wasm <b>&rightarrow;</b> C</center></td></tr>
                <td><strong>User machine:</strong></td><td><center>C <b>&rightarrow;</b> native</center></td></tr>
              </tr>
            </table>
          </p>
          <hr>
          <p>
            That C code is easy to compile since there is
            a C compiler everywhere (e.g. source could be c++20, rust nightly, etc.)
          </p>
        </section>

        <section>
          <h3><b>Benchmark results</b></h3>
          <hr>
					<a href="wasm2c-results.png"><img data-src="wasm2c-results.png" alt="benchmark results"></a>
        </section>

        <section>
          <h3><b>A surprising speed benefit</b></h3>
          <p>
            X32 arch benefits, 30% less memory
            30% faster on lua-binarytrees, 20% on havlak
          </p>
          <hr>
          <p>
          </p>
        </section>

        <section>
          <h3><b>Current status</b></h3>
          <hr>
          <p>
            The C code builds on clang and gcc on all platforms, but we could
            use some help with MSVC and others (we use e.g. <code>__builtin_ctlz</code>).
          </p>
          <hr>
          <p>
            Currently a single big C file is emitted which
            takes a while to compile on -O2. We should split into separate files.
          </p>
        </section>

        <section>
          <p>
            wasm2c integration in Emscripten supports practically everything
            normal wasm can do, including setjmp, files, most C++ features.
          </p>
          <hr>
          <p>
            However, this is all quite new and a few things are still missing
            like C++ exceptions.
          </p>
        </section>

        <section>
          <h3><b>Conclusion</b></h3>
          <hr>
          <p>
            VM-less wasm with wasm2c works surprisingly well! Can be useful today.
          </p>
          <hr>
          <p>
            In the long term, will we need this?
          </p>
        </section>

        <section>
          <h3><b>Thank you!</b></h3>
          <hr>
          <p>
            Questions?
          </p>
        </section>

<!--http://mozakai.blogspot.com/2013/05/the-elusive-universal-web-bytecode.html-->

      </div>


    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/search/search.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>

      // Also available as an ES module, see:
      // https://revealjs.com/initialization/
      Reveal.initialize({
        controls: true,
        progress: true,
        center: true,
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
      });

    </script>

  </body>
</html>
